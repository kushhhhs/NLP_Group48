{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "import math\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def clean_word(word):\n",
    "    '''Remove special characters and convert to lowercase.'''\n",
    "\n",
    "    word = word.lower().strip()\n",
    "    return re.sub(r'[^a-zA-Z]', '', word)\n",
    "\n",
    "\n",
    "def load_corpus_from_txt(filename):\n",
    "   \n",
    "    '''Load and split a text file into sentences of words.'''\n",
    "    \n",
    "    with open(filename, 'r') as file:\n",
    "        text = file.read()\n",
    "    sentences = re.split(r'[.!?]', text)\n",
    "\n",
    "    tokenized_sentences = []\n",
    "    for sentence in sentences:\n",
    "        if sentence.strip():  # ensure sentence is not empty or just a white space \n",
    "            tokens = re.findall(r'\\b\\w+\\b', sentence)\n",
    "            tokenized_sentences.append(tokens)\n",
    "\n",
    "    return tokenized_sentences\n",
    "\n",
    "\n",
    "def compute_pmi_ppmi(sentences, min_freq=10):\n",
    "    '''Method to compute PMI and PPMI for word bigrams. Returns a dataframe containing the all the word pairs and the PMI and PPMI values '''\n",
    "    all_words = []# list to stoare all the cleaned words in the corpora \n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            cleaned = clean_word(word)\n",
    "            all_words.append(cleaned)\n",
    "\n",
    "    total_words = len(all_words)\n",
    "\n",
    "    word_counts = Counter(all_words)\n",
    "    \n",
    "    valid_words = set()\n",
    "    \n",
    "    for word, count in word_counts.items():\n",
    "        if count >= min_freq:\n",
    "            valid_words.add(word) # Only add words which occur more than or equal to the minimum frequency specified we consider it to be 10\n",
    "\n",
    "    bigram_counts = Counter()\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        sentence = [clean_word(word) for word in sentence]\n",
    "        for i in range(len(sentence) - 1):\n",
    "            if sentence[i] in valid_words and sentence[i+1] in valid_words:\n",
    "                bigram_counts[(sentence[i], sentence[i+1])] += 1 # number of word pair occurances \n",
    "\n",
    "    pmi_data = []\n",
    "    for (w1, w2), bigram_count in bigram_counts.items():\n",
    "        p_w1 = word_counts[w1]/total_words\n",
    "        p_w2 = word_counts[w2]/total_words\n",
    "        p_bigram = bigram_count/(total_words - len(sentences))  # probability of a bigram(w1, w2) appearing\n",
    "\n",
    "        pmi = math.log2(p_bigram/(p_w1 * p_w2)) # Calculating pmi\n",
    "        ppmi = max(pmi, 0) # Removing any negative pmi values \n",
    "\n",
    "        pmi_data.append({\"word1\": w1, \"word2\": w2, \"pmi\": pmi, \"ppmi\": ppmi, \"count\": bigram_count})\n",
    "\n",
    "    df = pd.DataFrame(pmi_data)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_analysis(sentence=None, save_txt=False):\n",
    "    '''Function to run analysis on specified Corpus '''\n",
    "    \n",
    "    if sentence is None:\n",
    "        sentence = brown.sents()\n",
    "\n",
    "    df= compute_pmi_ppmi(sentence)\n",
    "    \n",
    "    top_pmi = df.sort_values(by=\"pmi\", ascending=False).head(20)\n",
    "    top_ppmi = df.sort_values(by=\"ppmi\", ascending=False).head(20)\n",
    "    bottom_pmi = df.sort_values(by=\"pmi\", ascending=True).head(20)\n",
    "    \n",
    "    output = []\n",
    "    output.append(\"Top 20 PMI pairs:\")\n",
    "    output.append(top_pmi.to_string(index=False))\n",
    "    output.append(\"Bottom 20 PMI pairs:\")\n",
    "    output.append(bottom_pmi.to_string(index=False))\n",
    "    output.append(\"Top 20 PPMI pairs:\")\n",
    "    output.append(top_ppmi.to_string(index=False))\n",
    "\n",
    "    full_output = \"\\n\\n\".join(output)\n",
    "    print(full_output)\n",
    "\n",
    "    if save_txt:\n",
    "        with open(\"pmi_ppmi_summary.txt\", \"w\") as f:\n",
    "            f.write(full_output)\n",
    "        print(\" Summary saved to 'pmi_ppmi_summary.txt' \")\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Analysis of the Entire Borwn Corpus\")\n",
    "run_analysis(save_txt=False)\n",
    "# We observe very High PMI values for proper noun collocations such as ('viet','nam') and negative values for function word pairs such as 'the', 'and' \n",
    "# eventhough the words occur frequently, they are gramatically incorrect when used together.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Analysis for brown100.txt\")\n",
    "brown100_sentence = load_corpus_from_txt('../data/brown_100.txt')\n",
    "run_analysis(sentence=brown100_sentence, save_txt=False)\n",
    "# Rare word pair may artifically inflate the PMI, for example ('certain', 'questions') have a PMI of almost 14 with just 1 count in the corpus.\n",
    "#  Which is a consequence of the small denominator value even if the signficance is low.\n",
    "# We can concur that PMI is sensitive to low-frequency data making it robust for rare pairs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
